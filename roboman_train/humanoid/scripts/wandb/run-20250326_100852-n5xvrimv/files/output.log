[34m[1mwandb[0m: [33mWARNING[0m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /home/alexhuge/Documents/GitHub/RoboMan/roboman_train/logs/wsybot_ppo/Mar26_10-08-50_
################################################################################
                      [1m Learning iteration 0/10001 [0m

                       Computation: 11444 steps/s (collection: 85.490s, learning 0.405s)
               Value function loss: 0.0018
                    Surrogate loss: -0.0012
             Mean action noise std: 1.00
                       Mean reward: 0.01
               Mean episode length: 47.79
Mean episode rew_action_smoothness: -0.5077
         Mean episode rew_base_acc: 0.0000
      Mean episode rew_base_height: 0.0009
        Mean episode rew_collision: -0.0007
Mean episode rew_default_joint_pos: 0.0010
          Mean episode rew_dof_acc: -0.0025
          Mean episode rew_dof_vel: -0.0030
    Mean episode rew_feet_air_time: 0.0007
   Mean episode rew_feet_clearance: 0.0006
Mean episode rew_feet_contact_forces: -0.0031
Mean episode rew_feet_contact_number: 0.0100
    Mean episode rew_feet_distance: 0.0037
        Mean episode rew_foot_slip: -0.0011
        Mean episode rew_joint_pos: 0.0103
    Mean episode rew_knee_distance: 0.0035
        Mean episode rew_low_speed: -0.0045
      Mean episode rew_orientation: 0.0058
          Mean episode rew_torques: -0.0010
   Mean episode rew_track_vel_hard: -0.0101
 Mean episode rew_tracking_ang_vel: 0.0028
 Mean episode rew_tracking_lin_vel: 0.0077
 Mean episode rew_vel_mismatch_exp: 0.0027
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 85.89s
                        Total time: 85.89s
                               ETA: 859031.0s

################################################################################
                      [1m Learning iteration 1/10001 [0m

                       Computation: 33703 steps/s (collection: 28.699s, learning 0.468s)
               Value function loss: 0.0021
                    Surrogate loss: -0.0001
             Mean action noise std: 1.00
                       Mean reward: 0.01
               Mean episode length: 45.46
Mean episode rew_action_smoothness: -0.7693
         Mean episode rew_base_acc: 0.0001
      Mean episode rew_base_height: 0.0010
        Mean episode rew_collision: -0.0009
Mean episode rew_default_joint_pos: 0.0010
          Mean episode rew_dof_acc: -0.0043
          Mean episode rew_dof_vel: -0.0050
    Mean episode rew_feet_air_time: 0.0010
   Mean episode rew_feet_clearance: 0.0009
Mean episode rew_feet_contact_forces: -0.0045
Mean episode rew_feet_contact_number: 0.0151
    Mean episode rew_feet_distance: 0.0056
        Mean episode rew_foot_slip: -0.0016
        Mean episode rew_joint_pos: 0.0137
    Mean episode rew_knee_distance: 0.0050
        Mean episode rew_low_speed: -0.0063
      Mean episode rew_orientation: 0.0062
          Mean episode rew_torques: -0.0016
   Mean episode rew_track_vel_hard: -0.0171
 Mean episode rew_tracking_ang_vel: 0.0037
 Mean episode rew_tracking_lin_vel: 0.0098
 Mean episode rew_vel_mismatch_exp: 0.0039
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 29.17s
                        Total time: 115.06s
                               ETA: 575309.7s
Traceback (most recent call last):
  File "train.py", line 50, in <module>
    train(args)
  File "train.py", line 42, in train
    ppo_runner.learn(
  File "/home/alexhuge/Documents/GitHub/RoboMan/roboman_train/humanoid/algo/ppo/on_policy_runner.py", line 130, in learn
    obs, privileged_obs, rewards, dones, infos = self.env.step(actions)
  File "/home/alexhuge/Documents/GitHub/RoboMan/roboman_train/humanoid/envs/custom/wsybot_env.py", line 210, in step
    return super().step(actions)
  File "/home/alexhuge/Documents/GitHub/RoboMan/roboman_train/humanoid/envs/base/legged_robot.py", line 104, in step
    self.gym.simulate(self.sim)
KeyboardInterrupt
